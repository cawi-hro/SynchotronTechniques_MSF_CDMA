{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6dd74b",
   "metadata": {},
   "source": [
    "## Image processing - segmentation and morphological operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ec831",
   "metadata": {},
   "source": [
    "By going through this jupyter notebook and filling in the blanks you will learn how to **extract specific features** of an image using tresholding and edge detection. Further, you will learn about **morphological operators**.\n",
    "\n",
    "The example code and solutions were created by **AndrÃ© Lopes Marinho** and **Berit Zeller-Plumhoff**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99dd9b",
   "metadata": {},
   "source": [
    "You will require the following libraries. If loading any of them fails, please use ``pip install`` to install any missing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "581e3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import ipympl\n",
    "import imageio.v3 as iio\n",
    "import skimage\n",
    "from skimage import draw\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab9cfb",
   "metadata": {},
   "source": [
    "---\n",
    "### Loading relevant functions from the previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08377d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_show_image(path):\n",
    "    \"\"\"\n",
    "    Load and display an image from the given path.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the image file, including the file extension.\n",
    "                    Example: \"images/example.tif\"\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The image data as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Use imageio to read the image\n",
    "    image = iio.imread(path)\n",
    "\n",
    "    # Display the image in grayscale using matplotlib\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()  # Ensure the image is displayed\n",
    "\n",
    "    # Print a success message\n",
    "    print(f\"The image from {path} was loaded successfully.\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_histogram(image):\n",
    "    \"\"\"Showns an histogram given an image. This method considers the image will be\n",
    "        either grayscale or RGB\n",
    "\n",
    "    Args:\n",
    "        img(numpy.ndarray): Image represented by array\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # First, we need to know if the image is grayscale or RGB\n",
    "    # use the shape function to do so\n",
    "    image_shape = image.shape\n",
    "\n",
    "    # Next, we can define some properties of our histogram figure\n",
    "    # create an empty figure with title, xlabel, ylabel and set the limits of the x-axis\n",
    "    plt.figure()\n",
    "    plt.title(\"Histogram\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Pixel count\")\n",
    "    plt.xlim([0, np.max(image)])\n",
    "\n",
    "    # Finally, create a histrogram using the numpy histogram function and plot it\n",
    "    # use a bin number of 256 in all cases\n",
    "    if len(image_shape) > 2:\n",
    "        colors = (\"red\", \"green\", \"blue\")\n",
    "        for channel_id, color in enumerate(colors):\n",
    "            histogram, bin_edges = np.histogram(\n",
    "                image[:, :, channel_id],\n",
    "                bins=256,\n",
    "                range=(0, np.max(image[:, :, channel_id])),\n",
    "            )\n",
    "            plt.plot(bin_edges[0:-1], histogram, color=color)\n",
    "    else:\n",
    "        histogram, bin_edges = np.histogram(image, bins=256, range=(0, np.max(image)))\n",
    "        plt.plot(bin_edges[0:-1], histogram)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def median_filter(image, filter_size):\n",
    "    \"\"\"Applies median filter in a given image.\n",
    "\n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be filtered\n",
    "        filter_size(int): Size of kernel\n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "\n",
    "    temp = []\n",
    "    padding = filter_size // 2\n",
    "    img_final = np.zeros((image.shape))\n",
    "\n",
    "    img_aux = np.zeros((image.shape[0] + padding * 2, image.shape[1] + padding * 2))\n",
    "    img_aux[padding:-padding, padding:-padding] = image.copy()\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            temp = img_aux[i : i + filter_size, j : j + filter_size]\n",
    "            img_final[i][j] = np.median(temp)\n",
    "\n",
    "    return img_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2267e",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccfd04",
   "metadata": {},
   "source": [
    "In the following, you will become familar with a number of different methods for feature extraction including **thresholding** and first and second order **edge detection**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc1829",
   "metadata": {},
   "source": [
    "#### Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344433fa",
   "metadata": {},
   "source": [
    "To set sensible thresholds you should consider the histogram of an image after loading it. Load the ``08_soil_and_roots_8bit_2.png`` image, apply a **median filter** and consider the **histogram** before and after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089db367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure images display in the Jupyter notebook as static image, interactive widget or in a seperate window. [inline, widget, qt]\n",
    "%matplotlib inline\n",
    "\n",
    "# load the image used for the exercise and show it\n",
    "image_raw = load_and_show_image(path=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_median = median_filter(, )\n",
    "\n",
    "# Plot the figures raw and median filtered\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(image_raw, cmap=\"gray\")\n",
    "ax2.imshow(image_median, cmap=\"gray\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot the histograms\n",
    "show_histogram(image=)\n",
    "show_histogram(image=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d435852",
   "metadata": {},
   "source": [
    "Write a function that will threshold an input image within the range specified as input to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca64337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(image, low_thresh, up_thresh):\n",
    "    \"\"\"Applies a threshold to a given image.\n",
    "\n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be thresholded\n",
    "        low_thresh(scalar): Value of lower threshold\n",
    "        up_thresh(scalar): Value of upper threshold\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Thresholded image\n",
    "    \"\"\"\n",
    "    img_back = np.zeros((image.shape))\n",
    "    img_back2 = np.zeros((image.shape))\n",
    "    img_back[np.where(image)] = 1\n",
    "    img_back2[np.where()] = 1\n",
    "    img_back = img_back * img_back2\n",
    "\n",
    "    return img_back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce4b14",
   "metadata": {},
   "source": [
    "You should see four peaks in the histogram of the filtered image. Apply the thresholding function for each of these peaks and plot the resulting images, as well as the input image, next to each other. Give each image a detail of what it represents.\n",
    "\n",
    "Play around with the performance of different image filters and kernel sizes and the regions you can subsequently segment using thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a73664",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = threshold(image_median, 0, 69)\n",
    "out2 = threshold(image_median, 70, 100)\n",
    "out3 = threshold(image_median, 101, 251)\n",
    "out4 = threshold(image_median, 252, 255)\n",
    "plt.subplot(151), plt.imshow(image_median, cmap=\"gray\")\n",
    "plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(152), plt.imshow(out, cmap=\"gray\")\n",
    "plt.title(\"Air\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(153), plt.imshow(out2, cmap=\"gray\")\n",
    "plt.title(\"Roots\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(154), plt.imshow(out3, cmap=\"gray\")\n",
    "plt.title(\"Soil\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(155), plt.imshow(out4, cmap=\"gray\")\n",
    "plt.title(\"Rocks\"), plt.xticks([]), plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8033aa00",
   "metadata": {},
   "source": [
    "#### First order edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573c806a",
   "metadata": {},
   "source": [
    "In **first order edge detection**, the gradient image of the original image is determined and local maxima are then identified. The resulting edge image may either be binary, i.e. already a thresholded version of the local maxima, depending on which step height should be included, or a greyscale image where each greyscale corresponds to the magnitude of the maximum.\n",
    "\n",
    "Because the process of implementing such a filter is complex, have a look [here](https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123)\n",
    "and try to implement the filter and workflow given there in order to **finally retrieve the edges** between **the soil and the air** and **the roots and the soil**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf3f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def sobel_filters(img):\n",
    "    Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "    Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "\n",
    "    Ix = ndimage.filters.convolve(img, Kx)\n",
    "    Iy = ndimage.filters.convolve(img, Ky)\n",
    "\n",
    "    G = np.hypot(Ix, Iy)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Iy, Ix)\n",
    "\n",
    "    return (G, theta)\n",
    "\n",
    "\n",
    "def non_max_suppression(img, D):\n",
    "    M, N = img.shape\n",
    "    Z = np.zeros((M, N), dtype=np.int32)\n",
    "    angle = D * 180.0 / np.pi\n",
    "    angle[angle < 0] += 180\n",
    "\n",
    "    for i in range(1, M - 1):\n",
    "        for j in range(1, N - 1):\n",
    "            try:\n",
    "                q = 255\n",
    "                r = 255\n",
    "\n",
    "                # angle 0\n",
    "                if (0 <= angle[i, j] < 22.5) or (157.5 <= angle[i, j] <= 180):\n",
    "                    q = img[i, j + 1]\n",
    "                    r = img[i, j - 1]\n",
    "                # angle 45\n",
    "                elif 22.5 <= angle[i, j] < 67.5:\n",
    "                    q = img[i + 1, j - 1]\n",
    "                    r = img[i - 1, j + 1]\n",
    "                # angle 90\n",
    "                elif 67.5 <= angle[i, j] < 112.5:\n",
    "                    q = img[i + 1, j]\n",
    "                    r = img[i - 1, j]\n",
    "                # angle 135\n",
    "                elif 112.5 <= angle[i, j] < 157.5:\n",
    "                    q = img[i - 1, j - 1]\n",
    "                    r = img[i + 1, j + 1]\n",
    "\n",
    "                if (img[i, j] >= q) and (img[i, j] >= r):\n",
    "                    Z[i, j] = img[i, j]\n",
    "                else:\n",
    "                    Z[i, j] = 0\n",
    "\n",
    "            except IndexError as e:\n",
    "                pass\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2478def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_edge(img, lowThresholdRatio=0.05, highThresholdRatio=0.09):\n",
    "    highThreshold = img.max() * highThresholdRatio\n",
    "    lowThreshold = highThreshold * lowThresholdRatio\n",
    "    M, N = img.shape\n",
    "    res = np.zeros((M, N), dtype=np.int32)\n",
    "\n",
    "    weak = np.int32(25)\n",
    "    strong = np.int32(255)\n",
    "\n",
    "    strong_i, strong_j = np.where(img >= highThreshold)\n",
    "    zeros_i, zeros_j = np.where(img < lowThreshold)\n",
    "\n",
    "    weak_i, weak_j = np.where((img <= highThreshold) & (img >= lowThreshold))\n",
    "\n",
    "    res[strong_i, strong_j] = strong\n",
    "    res[weak_i, weak_j] = weak\n",
    "\n",
    "    return (res, weak, strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e72ed5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis(img, weak, strong=255):\n",
    "    M, N = img.shape\n",
    "    for i in range(1, M - 1):\n",
    "        for j in range(1, N - 1):\n",
    "            if img[i, j] == weak:\n",
    "                try:\n",
    "                    if (\n",
    "                        (img[i + 1, j - 1] == strong)\n",
    "                        or (img[i + 1, j] == strong)\n",
    "                        or (img[i + 1, j + 1] == strong)\n",
    "                        or (img[i, j - 1] == strong)\n",
    "                        or (img[i, j + 1] == strong)\n",
    "                        or (img[i - 1, j - 1] == strong)\n",
    "                        or (img[i - 1, j] == strong)\n",
    "                        or (img[i - 1, j + 1] == strong)\n",
    "                    ):\n",
    "                        img[i, j] = strong\n",
    "                    else:\n",
    "                        img[i, j] = 0\n",
    "                except IndexError as e:\n",
    "                    pass\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_all = out2 + out3 + out4\n",
    "soil_sobel, theta = sobel_filters(soil_all)\n",
    "soil_max = non_max_suppression(soil_sobel, theta)\n",
    "soil_edge, weak, strong = threshold_edge(\n",
    "    soil_max, lowThresholdRatio=0.05, highThresholdRatio=0.09\n",
    ")\n",
    "soil_air = hysteresis(soil_edge, weak, strong=255)\n",
    "plt.figure()\n",
    "plt.imshow(soil_air, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be8fea7",
   "metadata": {},
   "source": [
    "---\n",
    "### Morphological operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd87ac3",
   "metadata": {},
   "source": [
    "To easily clean up our image, we can use **morphological operators**, such as **erosion and dilation**. In the following, you should implement these as functions that take the binarized image and the kernel size for the (quadratric) operator as input and output the processed image.\n",
    "Keep in mind that **you need to consider the image edges differently than during filtering**, i.e. padding may not be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9673d3d1",
   "metadata": {},
   "source": [
    "#### Erosion operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224b608",
   "metadata": {},
   "source": [
    "First, write a function to apply an erosion operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d1e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion_op(image, filter_size):\n",
    "    \"\"\"Applies erosion operator to a given binary image.\n",
    "\n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be processed, should contain only 0 and 1\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "    img_final = np.zeros((image.shape))\n",
    "    a = np.where(image == 1)[0]\n",
    "    b = np.where(image == 1)[1]\n",
    "\n",
    "    for i in range(0, a.shape[0]):\n",
    "        temp = np.zeros((filter_size, filter_size))\n",
    "        if a[i] - filter_size // 2 < 0:\n",
    "            if b[i] - filter_size // 2 < 0:\n",
    "                temp = image[\n",
    "                    0 : a[i] + filter_size // 2 + 1, 0 : b[i] + filter_size // 2 + 1\n",
    "                ]\n",
    "            else:\n",
    "                temp = image[\n",
    "                    0 : a[i] + filter_size // 2 + 1,\n",
    "                    b[i] - filter_size // 2 : b[i] + filter_size // 2 + 1,\n",
    "                ]\n",
    "        elif b[i] - filter_size // 2 < 0:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                0 : b[i] + filter_size // 2 + 1,\n",
    "            ]\n",
    "        elif a[i] + filter_size // 2 > image.shape[0]:\n",
    "            if b[i] + filter_size // 2 > image.shape[1]:\n",
    "                temp = image[a[i] - filter_size // 2 : -1, b[i] - filter_size // 2 : -1]\n",
    "            else:\n",
    "                temp = image[\n",
    "                    a[i] - filter_size // 2 : -1,\n",
    "                    b[i] - filter_size // 2 : b[i] + filter_size // 2,\n",
    "                ]\n",
    "        elif b[i] + filter_size // 2 > image.shape[1]:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                b[i] - filter_size // 2 : -1,\n",
    "            ]\n",
    "        else:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                b[i] - filter_size // 2 : b[i] + filter_size // 2 + 1,\n",
    "            ]\n",
    "        if 0 in temp:\n",
    "            img_final[a[i]][b[i]] = 1\n",
    "    img_final = image - img_final\n",
    "\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3029e",
   "metadata": {},
   "source": [
    "Apply the erosion operator to the thresholded image of the root with different kernel sizes and comment on how the image changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "erode_root = erosion_op(, )\n",
    "plt.imshow(erode_root, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bf09b",
   "metadata": {},
   "source": [
    "#### Dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace76ea2",
   "metadata": {},
   "source": [
    "Now write a function for a dilation operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35381422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilation_op(image, filter_size):\n",
    "    \"\"\"Applies dilation operator to a given binary image.\n",
    "\n",
    "    Args:\n",
    "        image(numpy.ndarray): Image to be processed, should contain only 0 and 1\n",
    "        filter_size(numpy.ndarray): Size of kernel\n",
    "    Returns:\n",
    "        numpy.ndarray: Filtered image\n",
    "    \"\"\"\n",
    "\n",
    "    img_final = np.zeros((image.shape))\n",
    "    a = np.where(image == 0)[0]\n",
    "    b = np.where(image == 0)[1]\n",
    "\n",
    "    for i in range(0, a.shape[0]):\n",
    "        temp = np.zeros((filter_size, filter_size))\n",
    "        if a[i] - filter_size // 2 < 0:\n",
    "            if b[i] - filter_size // 2 < 0:\n",
    "                temp = image[\n",
    "                    0 : a[i] + filter_size // 2 + 1, 0 : b[i] + filter_size // 2 + 1\n",
    "                ]\n",
    "            else:\n",
    "                temp = image[\n",
    "                    0 : a[i] + filter_size // 2 + 1,\n",
    "                    b[i] - filter_size // 2 : b[i] + filter_size // 2 + 1,\n",
    "                ]\n",
    "        elif b[i] - filter_size // 2 < 0:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                0 : b[i] + filter_size // 2 + 1,\n",
    "            ]\n",
    "        elif a[i] + filter_size // 2 > image.shape[0]:\n",
    "            if b[i] + filter_size // 2 > image.shape[1]:\n",
    "                temp = image[a[i] - filter_size // 2 : -1, b[i] - filter_size // 2 : -1]\n",
    "            else:\n",
    "                temp = image[\n",
    "                    a[i] - filter_size // 2 : -1,\n",
    "                    b[i] - filter_size // 2 : b[i] + filter_size // 2,\n",
    "                ]\n",
    "        elif b[i] + filter_size // 2 > image.shape[1]:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                b[i] - filter_size // 2 : -1,\n",
    "            ]\n",
    "        else:\n",
    "            temp = image[\n",
    "                a[i] - filter_size // 2 : a[i] + filter_size // 2 + 1,\n",
    "                b[i] - filter_size // 2 : b[i] + filter_size // 2 + 1,\n",
    "            ]\n",
    "        if 1 in temp:\n",
    "            img_final[a[i]][b[i]] = 1\n",
    "    img_final = image + img_final\n",
    "\n",
    "    return img_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f284b",
   "metadata": {},
   "source": [
    "Apply the dilation operator to the eroded image of the root with different kernel sizes and comment on how the image changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56788caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dil_root = dilation_op(, )\n",
    "plt.imshow(dil_root, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043123c",
   "metadata": {},
   "source": [
    "Now plot original image next to the eroded and dilated one, as well as a dilated and eroded one. What differences do you see between the images if you apply kernel sizes of 3 and 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454dc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dil_root2 = dilation_op(, )\n",
    "erode_root2 = erosion_op(, )\n",
    "plt.figure()\n",
    "plt.subplot(151), plt.imshow(out2, cmap=\"gray\")\n",
    "plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(152), plt.imshow(erode_root, cmap=\"gray\")\n",
    "plt.title(\"Erosion\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(153), plt.imshow(dil_root, cmap=\"gray\")\n",
    "plt.title(\"Erosion+\\n Dilation\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(154), plt.imshow(dil_root2, cmap=\"gray\")\n",
    "plt.title(\"Dilation\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(155), plt.imshow(erode_root2, cmap=\"gray\")\n",
    "plt.title(\"Dilation+\\n Erosion\"), plt.xticks([]), plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302709e",
   "metadata": {},
   "source": [
    "**Comment:**  \n",
    "The images show clearly, that the order in which dilation and erosion operator are applied influences the outcome significantly. If we first perform an erosion, we get rid of thin structures, such as the edges and we increase holes present in the root for example. By then applying the dilation operation, we close these holes again and bring the structures back to their original size, while the undesired edges remain removed. By contrast, if we first perform a dilation, then all structures are magnified and holes present in the root are closed. The subsequent erosion shrinks the structures, but any holes that have been closed remain so and the edges are still present in the figure. \n",
    "Based on this observation it is apparent, why the _opening_ operation is an erosion followed by a dilation and why the _closing_ operation is a dilation followed by an erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e551c74c",
   "metadata": {},
   "source": [
    "---\n",
    "### Distance transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef6510",
   "metadata": {},
   "source": [
    "Use the ``scipy`` distance transform ``distance_transform_ed`` and try to recreate the workflow shown in the lecture.\n",
    "Starting with the original image ``08_soil_and_roots_8bit_2.png``, filter it, threshold the soil and the root, try to clean the image as musch as possible and apply the distance transform to both images and by multiplying the output obtain the final image where you will have the distance to the root in all soil pixel.\n",
    "Plot the different intermediate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = threshold(image_median, 70, 100)\n",
    "soil = threshold(image_median, 101, 255)\n",
    "erode_root = erosion_op(root, 3)\n",
    "dil_root = dilation_op(erode_root, 3)\n",
    "root_inv = np.ones(root.shape) - dil_root\n",
    "dist_root = distance_transform_edt(root_inv)\n",
    "soil_dist_root = soil * dist_root\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(151), plt.imshow(image_raw, cmap=\"gray\")\n",
    "plt.title(\"Input Image\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(152), plt.imshow(soil, cmap=\"gray\")\n",
    "plt.title(\"Soil\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(153), plt.imshow(root_inv, cmap=\"gray\")\n",
    "plt.title(\"Root inverted\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(154), plt.imshow(dist_root, cmap=\"gray\")\n",
    "plt.title(\"Distance\"), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(155), plt.imshow(soil_dist_root, cmap=\"gray\")\n",
    "plt.title(\"Final\"), plt.xticks([]), plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95a148",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
